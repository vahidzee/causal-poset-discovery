{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from ocd.models.oslow import OSlowTest\n",
    "from ocd.data.synthetic.graph_generator import GraphGenerator\n",
    "from ocd.data.synthetic.utils import RandomGenerator\n",
    "from ocd.data.synthetic.parametric import AffineParametericDataset\n",
    "from ocd.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from ocd.models.normalization import ActNorm\n",
    "from ocd.training.trainer import Trainer\n",
    "from ocd.config import GumbelTopKConfig, BirkhoffConfig, GumbelSinkhornStraightThroughConfig, ContrastiveDivergenceConfig\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = 'cuda:0'\n",
    "print(device)\n",
    "\n",
    "num_samples = 128\n",
    "permutation_batch_size = 128\n",
    "flow_batch_size = 128\n",
    "epochs = 100\n",
    "flow_lr = 0.0001\n",
    "perm_lr = 0.000001\n",
    "flow_freq = 500\n",
    "perm_freq = 4\n",
    "num_nodes = 4\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_nodes,\n",
    "    seed=12,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[i for i in range(num_nodes)],\n",
    ")\n",
    "graph = graph_generator.generate_dag()\n",
    "\n",
    "# These generators are also needed to generate the data\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=30, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=1100, low=1, high=1)\n",
    "\n",
    "# parameteric with sin(x) + x non-linearity and softplus\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph=graph,\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    ")\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "\n",
    "dataset = CustomTensorDataset(torch.tensor(dset_sinusoidal.samples.values).float())\n",
    "flow_dataloader = DataLoader(dataset, batch_size=flow_batch_size, shuffle=True)\n",
    "permutation_dataloader = DataLoader(dataset, batch_size=permutation_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 02:28:50 ERROR    Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhamidrezakamkari\u001b[0m (\u001b[33mordered-causal-discovery\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hamid/ocdaf/notebooks/wandb/run-20240208_022851-51jc0pi7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/51jc0pi7' target=\"_blank\">stellar-music-89</a></strong> to <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/51jc0pi7' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks/runs/51jc0pi7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0687d35931e4098a0006cac282b1961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='12.950 MB of 12.950 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>flow/loss</td><td>█▇▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▄▄▅▄▄▄▄▄▄▃▂▃▃▃▂▃▃▃▂▂▂▁</td></tr><tr><td>flow/step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>permutation/avg_backward_penalty</td><td>▁▂▂▂▂▃▂▃▂▃▂▂▂▂▂▁▁▂▂▂▂▃▂▂▂▂▁▂▂▂▁▂▁▁▂▂▂▂▁█</td></tr><tr><td>permutation/best_backward_penalty</td><td>▁▂▂▂▅▅▅▅▅▅▅▇▅▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇▇▇▂▇▇▇▇</td></tr><tr><td>permutation/loss</td><td>█▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▁</td></tr><tr><td>permutation/step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>permutation/temperature</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>flow/loss</td><td>8.0647</td></tr><tr><td>flow/step</td><td>50000</td></tr><tr><td>permutation/avg_backward_penalty</td><td>0.83333</td></tr><tr><td>permutation/best_backward_penalty</td><td>0.83333</td></tr><tr><td>permutation/loss</td><td>8.06929</td></tr><tr><td>permutation/step</td><td>400</td></tr><tr><td>permutation/temperature</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-music-89</strong> at: <a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/51jc0pi7' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks/runs/51jc0pi7</a><br/>Synced 5 W&B file(s), 400 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_022851-51jc0pi7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c92dd087b94408bbdb1a37853f24e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112532699998054, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hamid/ocdaf/notebooks/wandb/run-20240208_024759-84vo9nqs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/84vo9nqs' target=\"_blank\">lyric-armadillo-90</a></strong> to <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/84vo9nqs' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks/runs/84vo9nqs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m\n\u001b[1;32m     37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     38\u001b[0m                   dag\u001b[38;5;241m=\u001b[39mgraph,\n\u001b[1;32m     39\u001b[0m                   flow_dataloader\u001b[38;5;241m=\u001b[39mflow_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m                   birkhoff_config\u001b[38;5;241m=\u001b[39mbirkhoff_config,\n\u001b[1;32m     52\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     53\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebooks\u001b[39m\u001b[38;5;124m\"\u001b[39m, entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered-causal-discovery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m            tags\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     55\u001b[0m                permutation_learning_config\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-sigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m            ],)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/trainer.py:202\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch})\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_frequency):\n\u001b[0;32m--> 202\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_train_step(\n\u001b[1;32m    203\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_temperature(epoch))\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# logging.info(\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#     f\"Flow step {epoch * self.flow_frequency + i} / {self.max_epochs * self.flow_frequency}, flow loss: {loss.item()}\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_scheduler, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau\n\u001b[1;32m    209\u001b[0m     ):\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/trainer.py:136\u001b[0m, in \u001b[0;36mTrainer.flow_train_step\u001b[0;34m(self, temperature)\u001b[0m\n\u001b[1;32m    134\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 136\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation_learning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_learning_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/permutation.py:193\u001b[0m, in \u001b[0;36mPermutationMatrixLearningModule.flow_learning_loss\u001b[0;34m(self, model, batch, temperature)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_learning_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: OSlow, batch: torch\u001b[38;5;241m.\u001b[39mTensor, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 193\u001b[0m     permutations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_hard_permutations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_and_resample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgumbel_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    196\u001b[0m     log_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlog_prob(batch, perm_mat\u001b[38;5;241m=\u001b[39mpermutations)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlog_probs\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/permutation.py:181\u001b[0m, in \u001b[0;36mPermutationMatrixLearningModule.sample_hard_permutations\u001b[0;34m(self, num_samples, return_noises, unique_and_resample, gumbel_std)\u001b[0m\n\u001b[1;32m    172\u001b[0m     permutations \u001b[38;5;241m=\u001b[39m permutations[\n\u001b[1;32m    173\u001b[0m         torch\u001b[38;5;241m.\u001b[39mrandint(\n\u001b[1;32m    174\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m     ]\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# turn permutations into permutation matrices\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m ret \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([turn_into_matrix(perm) \u001b[38;5;28;01mfor\u001b[39;00m perm \u001b[38;5;129;01min\u001b[39;00m permutations])\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# add some random noise to the permutation matrices\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_noises:\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/permutation.py:181\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m     permutations \u001b[38;5;241m=\u001b[39m permutations[\n\u001b[1;32m    173\u001b[0m         torch\u001b[38;5;241m.\u001b[39mrandint(\n\u001b[1;32m    174\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m     ]\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# turn permutations into permutation matrices\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m ret \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mturn_into_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m perm \u001b[38;5;129;01min\u001b[39;00m permutations])\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# add some random noise to the permutation matrices\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_noises:\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/utils.py:23\u001b[0m, in \u001b[0;36mturn_into_matrix\u001b[0;34m(permutation)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mturn_into_matrix\u001b[39m(permutation: torch\u001b[38;5;241m.\u001b[39mIntTensor):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from ocd.models.oslow import OSlow\n",
    "import wandb\n",
    "\n",
    "torch.random.manual_seed(101)\n",
    "model = OSlow(in_features=num_nodes,\n",
    "              layers=[128, 64, 128],\n",
    "              dropout=None,\n",
    "              residual=False,\n",
    "              activation=torch.nn.LeakyReLU(),\n",
    "              additive=False,\n",
    "              num_transforms=1,\n",
    "              normalization=ActNorm,\n",
    "              base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "              ordering=None)\n",
    "\n",
    "\n",
    "def flow_optimizer(params): return torch.optim.AdamW(params, lr=flow_lr)\n",
    "def perm_optimizer(params): return torch.optim.AdamW(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "permutation_learning_config = GumbelTopKConfig(\n",
    "    num_samples=num_samples,\n",
    "    buffer_size=10,\n",
    "    buffer_update=10,\n",
    "    set_gamma_uniform=True,\n",
    ")\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "temperature_scheduler = 'linear'\n",
    "temperature = 1.0\n",
    "\n",
    "birkhoff_config = None if num_nodes > 4 else BirkhoffConfig(\n",
    "    num_samples=100, frequency=1, print_legend=False)\n",
    "trainer = Trainer(model=model,\n",
    "                  dag=graph,\n",
    "                  flow_dataloader=flow_dataloader,\n",
    "                  perm_dataloader=permutation_dataloader,\n",
    "                  flow_optimizer=flow_optimizer,\n",
    "                  permutation_optimizer=perm_optimizer,\n",
    "                  flow_frequency=flow_freq,\n",
    "                  temperature=temperature,\n",
    "                  temperature_scheduler=temperature_scheduler,\n",
    "                  permutation_frequency=perm_freq,\n",
    "                  max_epochs=epochs,\n",
    "                  flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_learning_config=permutation_learning_config,\n",
    "                  birkhoff_config=birkhoff_config,\n",
    "                  device=device)\n",
    "wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "            tags=[\n",
    "                permutation_learning_config.method,\n",
    "                f\"num_nodes-{num_nodes}\",\n",
    "                f\"epochs-{epochs}\",\n",
    "                f\"base-temperature-{temperature}\",\n",
    "                f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                \"no-sigmoid\",\n",
    "            ],)\n",
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
