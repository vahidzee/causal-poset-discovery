project: syntren-dysweep
default_root_dir: experiments/sweep
count: 10000

# BASE configuration which is being used
base_config:
  seed_everything: 111
  trainer:
    max_epochs: 1500
    accelerator: gpu
    devices: 1
    num_nodes: 0
    callbacks:
      - class_path: ocd.training.callbacks.data_visualizer.DataVisualizer
      - class_path: ocd.training.callbacks.phase_changer.PhaseChangerCallback
        init_args:
          starting_phase: maximization
          monitor_validation: false
          monitor_training: true
          maximization_epoch_limit: 100
          expectation_epoch_limit: 80
          patience: 15
          cooldown: 200
          threshold: 0.0001
          reset_optimizers: false
          reinitialize_weights_on_maximization: false
          log_onto_logger: true
      - class_path: ocd.training.callbacks.save_results.SavePermutationResultsCallback
        init_args:
          log_every_n_epochs: 5
          num_samples: 5000
          log_into_logger: true
    enable_checkpointing: true
    enable_progress_bar: false
    enable_model_summary: true
  data:
    class_path: lightning_toolbox.DataModule
    init_args:
      batch_size: 128
      dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
      val_size: 0.01
      dataset_args:
        data_id: 0
  model:
    class_path: ocd.training.module.OCDafTrainingModule
    init_args:
      model_cls: ocd.models.ocdaf.OCDAF
      model_args:
        use_permutation: true
        permutation_learner_cls: ocd.models.permutation.LearnablePermutation
        permutation_learner_args:
          permutation_type: gumbel-topk
          # change this if cuda out of limit happens
          gumbel_noise_std: |
            lambda self, training_module, **kwargs: 2 - (2 / (training_module.trainer.max_epochs)) * (training_module.current_epoch)
        base_distribution: torch.distributions.Normal
        base_distribution_args:
          loc: 0.0
          scale: 1.0
        layers:
          - 30
          - 10
          - 10
        populate_features: true
        layers_limit:
          - 300
          - 100
          - 50
        num_transforms: 1
        additive: false
        residual: false
        bias: true
        scale_transform: true
        scale_transform_s_args:
          pre_act_scale: 0.1
          post_act_scale: 10.0
        scale_transform_t_args:
          pre_act_scale: 0.01
          post_act_scale: 100.0
        activation: torch.nn.LeakyReLU
        activation_args:
          negative_slope: 0.1
      objective: null
      objective_cls: lightning_toolbox.Objective
      objective_args:
        nll:
          code: |
            def func(training_module, batch):
              t = training_module.forward(batch)
              res = t['log_prob']
              return -res.mean()
          function_of_interest: func
      optimizer:
        - torch.optim.AdamW
        - torch.optim.AdamW
      optimizer_is_active:
        - >
          lambda training_module: training_module.current_phase == 'maximization' if hasattr(training_module, 'current_phase') else True
        - >
          lambda training_module: training_module.current_phase == 'expectation' if hasattr(training_module, 'current_phase') else True
      optimizer_parameters:
        - model.flow
        - model.permutation_model
      optimizer_args:
        - weight_decay: 0.1
        - weight_decay: 0.01
      lr:
        - 0.01
        - 0.01
      scheduler:
        - torch.optim.lr_scheduler.ReduceLROnPlateau
        - torch.optim.lr_scheduler.ReduceLROnPlateau
      scheduler_name:
        - lr_scheduler_maximization
        - lr_scheduler_expectation
      scheduler_optimizer:
        - 0
        - 1
      scheduler_args:
        - mode: min
          factor: 0.5
          patience: 200
          min_lr: 1.0e-4
          threshold: 0.0001
        - mode: min
          factor: 0.5
          patience: 180
          min_lr: 1.0e-4
          threshold: 0.0001
      scheduler_interval: epoch
      scheduler_frequency: 1
      scheduler_monitor:
        - loss
        - loss
      save_hparams: true
      initialize_superclass: true

sweep_configuration:
  method: grid
  metric:
    goal: minimize
    name: metrics/best-backward_relative_penalty
  parameters:
    dy__upsert:
      - sweep: True
        sweep_identifier: B_dataset
        sweep_alias:
          - data0
          - data1
          - data2
          - data3
          - data4
          - data5
          - data6
          - data7
          - data8
          - data9
        values:
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 0
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 1
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 2
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 3
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 4
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 5
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 6
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 7
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 8
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
          - data:
              class_path: lightning_toolbox.DataModule
              init_args:
                batch_size: 128
                dataset: ocd.data.real_world.syntren.SyntrenOCDDataset
                val_size: 0.01
                dataset_args:
                  data_id: 9
                  standardization: True
                  reject_outliers_n_far_from_mean: 5.0
            model:
              init_args:
                model_args:
                  in_features: 20
      - trainer:
          callbacks:
            dy__list__operations:
              - dy__overwrite: 2
            init_args:
              save_path:
                dy__eval:
                  expression: |
                    def func(conf):
                      return f"experiments/saves/syntren/data-{conf['data']['init_args']['dataset_args']['data_id']}"
                  function_of_interest: func
              save_every_n_epochs: 500
